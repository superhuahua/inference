[metadata]
name = xinference
description = Model Serving Made Easy
author = Qin Xuye
author_email = qinxuye@xprobe.io
maintainer = Qin Xuye
maintainer_email = qinxuye@xprobe.io
license = Apache License 2.0
url = https://github.com/xorbitsai/inference
python_requires = >=3.8
classifier =
    Operating System :: OS Independent
    Programming Language :: Python
    Programming Language :: Python :: 3
    Programming Language :: Python :: 3.8
    Programming Language :: Python :: 3.9
    Programming Language :: Python :: 3.10
    Programming Language :: Python :: 3.11
    Programming Language :: Python :: Implementation :: CPython
    Topic :: Software Development :: Libraries

[options]
zip_safe = False
include_package_data = True
packages = find:
install_requires =
    xoscar>=0.2.1
    torch
    gradio>=3.39.0
    pillow
    click
    tqdm>=4.27
    tabulate
    requests
    pydantic<2
    fastapi
    uvicorn
    huggingface-hub>=0.14.1,<1.0
    typing_extensions
    fsspec
    s3fs
    modelscope>=1.10.0
    sse_starlette>=1.6.5  # ensure_bytes API break change: https://github.com/sysid/sse-starlette/issues/65
    openai>1  # For typing
    python-jose[cryptography]
    passlib[bcrypt]

[options.packages.find]
exclude =
    *.conftest*
    *.tests.*
    *.tests

[options.extras_require]
dev =
    cython>=0.29
    pytest>=3.5.0
    pytest-cov>=2.5.0
    pytest-timeout>=1.2.0
    pytest-forked>=1.0
    pytest-asyncio>=0.14.0
    pytest-mock>=3.11.1
    ipython>=6.5.0
    sphinx>=3.0.0
    pydata-sphinx-theme>=0.3.0
    sphinx-intl>=0.9.9
    jieba>=0.42.0
    flake8>=3.8.0
    black
    openai>1
    opencv-python
    langchain
    orjson
    sphinx-tabs
    sphinx-design
all =
    chatglm-cpp>=0.3.0
    ctransformers
    llama-cpp-python>=0.2.25
    transformers>=4.34.1
    torch
    accelerate>=0.20.3
    sentencepiece
    transformers_stream_generator
    bitsandbytes
    protobuf
    einops
    tiktoken
    sentence-transformers
    vllm>=0.2.6 ; sys_platform=='linux'
    diffusers
    controlnet_aux
    orjson
    auto-gptq ; sys_platform!='darwin'
    optimum
ggml =
    llama-cpp-python>=0.2.25
    ctransformers
    chatglm-cpp>=0.3.0
transformers =
    transformers>=4.34.1
    torch
    accelerate>=0.20.3
    sentencepiece
    transformers_stream_generator
    bitsandbytes
    protobuf
    einops
    tiktoken
    auto-gptq
    optimum
vllm =
    vllm>=0.2.6
embedding =
    sentence-transformers
image =
    diffusers
    controlnet_aux
doc =
    ipython>=6.5.0
    sphinx>=3.0.0
    pydata-sphinx-theme>=0.3.0
    sphinx-intl>=0.9.9
    sphinx-tabs
    sphinx-design
benchmark =
    psutil
    pynvml

[options.entry_points]
console_scripts =
    xinference = xinference.deploy.cmdline:cli
    xinference-local = xinference.deploy.cmdline:local
    xinference-supervisor = xinference.deploy.cmdline:supervisor
    xinference-worker = xinference.deploy.cmdline:worker

[coverage:run]
branch = True
relative_files = True
cover_pylib = False
plugins = Cython.Coverage
include =
    xinference/*
omit =
    xinference/_version.py
    *.pxd
    */tests/*

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    return NotImplemented

[versioneer]
VCS = git
style = pep440
versionfile_source = xinference/_version.py
versionfile_build = xinference/_version.py
tag_prefix = v
parentdir_prefix = xinference-

[flake8]
max-line-length = 100
select =
    E9,
    E101,
    E111,
    E117,
    E127,
    E201,
    E202,
    E223,
    E224,
    E225,
    E231,
    E242,
    E251,
    E273,
    E274,
    E275,
    E301,
    E302,
    E303,
    E304,
    E305,
    E401,
    E703,
    E901,
    E999,
    F7,
    F63,
    F82,
    F401,
    F811,
    F821,
    F822,
    F823,
    F841,
    W191,
    W291,
    W292,
    W293,
    W391,
    W601,
    W602,
    W603,
    W604,
    W605
exclude =
    __init__.py
    __pycache__
    .git/
    .github/
    build/
    ci/
    dist/
    docs/

[codespell]
ignore-words-list = hist,rcall,fpr,ser,nd,inout,ot,Ba,ba,asend,hart,coo,splitted,datas,fro
skip = .idea,.git,./build,./docs/build,node_modules,static,generated,*.po,*.ts,*.json,*.c,*.cpp,*.cfg

[isort]
profile = black

[mypy]
ignore_missing_imports=True
follow_imports=skip
